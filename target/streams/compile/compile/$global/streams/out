[0m[[0m[31merror[0m] [0m[0m/home/pal/IdeaProjects/KafkaReader/src/main/scala/Main.scala:63:21: overloaded method value foreachBatch with alternatives:[0m
[0m[[0m[31merror[0m] [0m[0m  (function: org.apache.spark.api.java.function.VoidFunction2[org.apache.spark.sql.Dataset[org.apache.spark.sql.Row],java.lang.Long])org.apache.spark.sql.streaming.DataStreamWriter[org.apache.spark.sql.Row] <and>[0m
[0m[[0m[31merror[0m] [0m[0m  (function: (org.apache.spark.sql.Dataset[org.apache.spark.sql.Row], scala.Long) => Unit)org.apache.spark.sql.streaming.DataStreamWriter[org.apache.spark.sql.Row][0m
[0m[[0m[31merror[0m] [0m[0m cannot be applied to ((org.apache.spark.sql.DataFrame, scala.Long, scala.Long) => Unit)[0m
[0m[[0m[31merror[0m] [0m[0m       .writeStream.foreachBatch { (batchDF: DataFrame, batchId: Long, count: Long) =>[0m
[0m[[0m[31merror[0m] [0m[0m                    ^[0m
[0m[[0m[31merror[0m] [0m[0mone error found[0m
